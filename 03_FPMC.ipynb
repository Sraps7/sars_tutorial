{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "1. [Load the dataset](#load_the_dataset)\n",
    "2. [Split the dataset](#split_the_dataset)\n",
    "3. [Fitting the recommender](#fitting)\n",
    "4. [Sequential evaluation](#seq_evaluation)  \n",
    "    4.1 [Evaluation with sequentially revaeled user profiles](#eval_seq_rev)  \n",
    "    4.2 [Evaluation with \"static\" user profiles](#eval_static)  \n",
    "5. [Analysis of next-item recommendation](#next-item)  \n",
    "    5.1 [Evaluation with different recommendation list lengths](#next-item_list_length)  \n",
    "    5.2 [Evaluation with different user profile lengths](#next-item_profile_length)\n",
    "    \n",
    "---------------------\n",
    "## **sraps**: \n",
    "    \n",
    "    FPMC无法支持冷启动。如果新来了一个用户，我们没有他的历史数据（听歌记录、购买记录等）\n",
    "    那么没法用FPMC对他的下一首歌或是下一项购买行为进行预测(推荐）\n",
    "    因为FPMC是基于个性化的推荐，它需要训练一个用户U与物品I之间的关系矩阵，\n",
    "    新用户在训练好的模型里是没有这个矩阵的。\n",
    "    \n",
    "    而新用户是可以在矩阵分解模型（非个性化）下给出预测的。\n",
    "    \n",
    "    我们可以考虑每个人（物）都具有共性和特性，在冷启动状态下，只能依照其共性进行推测，\n",
    "    其个性可以在产生历史记录后进行学习（各种模型）。\n",
    "    当然，也可以引入知识图谱，在冷启动状态，极大化其特性的猜测，根据用户提供信息的丰富度，\n",
    "    进行初始化特性与共性的比例调节。\n",
    "    \n",
    "    这篇文档实现的是seq到下一个item或下个seq的预测\n",
    "    可以考虑set到set的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.data_utils import create_seq_db_filter_top_k, sequences_to_spfm_format\n",
    "from util.split import last_session_out_split\n",
    "from util.metrics import precision, recall, mrr\n",
    "from util import evaluation\n",
    "from recommenders.FPMCRecommender import FPMCRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_sequences_and_users(test_data, given_k, train_users):\n",
    "    # we can run evaluation only over sequences longer than abs(LAST_K)\n",
    "    mask = test_data['sequence'].map(len) > abs(given_k)\n",
    "    mask &= test_data['user_id'].isin(train_users)\n",
    "    test_sequences = test_data.loc[mask, 'sequence'].values\n",
    "    test_users = test_data.loc[mask, 'user_id'].values\n",
    "    return test_sequences, test_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_the_dataset'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the dataset\n",
    "\n",
    "For this hands-on session we will use a dataset of user-listening sessions crawled from [last.fm](https://www.last.fm/). In detail, we will use a subset of the following dataset:\n",
    "\n",
    "* 30Music listening and playlists dataset, Turrin et al., ACM RecSys 2015 ([paper](https://home.deib.polimi.it/pagano/portfolio/papers/30Musiclisteningandplaylistsdataset.pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the dataset, if you haven't already done it\n",
    "# ! unzip datasets/sessions.zip -d datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\work\\ML_experiment\\two\\sars_tutorial\\util\\data_utils.py:24: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  aggregated = groups['item_id'].agg({'sequence': lambda x: list(map(str, x))})\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'datasets\\\\sessions\\\\sessions.csv'\n",
    "# load this sample if you experience a severe slowdown with the previous dataset\n",
    "#dataset_path = 'datasets/sessions_sample_10.csv'\n",
    "\n",
    "# for the sake of speed, let's keep only the top-1k most popular items in the last month\n",
    "dataset = create_seq_db_filter_top_k(path=dataset_path, topk=1000, last_months=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see at how the dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>ts</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122</td>\n",
       "      <td>[1762, 3700, 638]</td>\n",
       "      <td>1420059172</td>\n",
       "      <td>2432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>223</td>\n",
       "      <td>[3772, 3953]</td>\n",
       "      <td>1419418147</td>\n",
       "      <td>15861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>[245, 1271, 379]</td>\n",
       "      <td>1419433841</td>\n",
       "      <td>15861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>[245, 1197, 4307, 3868]</td>\n",
       "      <td>1421674741</td>\n",
       "      <td>15861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>245</td>\n",
       "      <td>[409, 234, 2334, 2431, 231, 4738, 219, 2403]</td>\n",
       "      <td>1421679507</td>\n",
       "      <td>15861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                                      sequence          ts  \\\n",
       "0         122                             [1762, 3700, 638]  1420059172   \n",
       "1         223                                  [3772, 3953]  1419418147   \n",
       "2         226                              [245, 1271, 379]  1419433841   \n",
       "3         243                       [245, 1197, 4307, 3868]  1421674741   \n",
       "4         245  [409, 234, 2334, 2431, 231, 4738, 219, 2403]  1421679507   \n",
       "\n",
       "   user_id  \n",
       "0     2432  \n",
       "1    15861  \n",
       "2    15861  \n",
       "3    15861  \n",
       "4    15861  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show some statistics about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "dataset.sequence.map(cnt.update);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 1000\n",
      "Number of users: 17850\n",
      "Number of sessions: 66249\n",
      "\n",
      "Session length:\n",
      "\tAverage: 4.19\n",
      "\tMedian: 3.0\n",
      "\tMin: 1\n",
      "\tMax: 198\n",
      "Sessions per user:\n",
      "\tAverage: 3.71\n",
      "\tMedian: 3.0\n",
      "\tMin: 1\n",
      "\tMax: 38\n"
     ]
    }
   ],
   "source": [
    "sequence_length = dataset.sequence.map(len).values\n",
    "n_sessions_per_user = dataset.groupby('user_id').size()\n",
    "\n",
    "print('Number of items: {}'.format(len(cnt)))\n",
    "print('Number of users: {}'.format(dataset.user_id.nunique()))\n",
    "print('Number of sessions: {}'.format(len(dataset)) )\n",
    "\n",
    "print('\\nSession length:\\n\\tAverage: {:.2f}\\n\\tMedian: {}\\n\\tMin: {}\\n\\tMax: {}'.format(\n",
    "    sequence_length.mean(), \n",
    "    np.quantile(sequence_length, 0.5), \n",
    "    sequence_length.min(), \n",
    "    sequence_length.max()))\n",
    "\n",
    "print('Sessions per user:\\n\\tAverage: {:.2f}\\n\\tMedian: {}\\n\\tMin: {}\\n\\tMax: {}'.format(\n",
    "    n_sessions_per_user.mean(), \n",
    "    np.quantile(n_sessions_per_user, 0.5), \n",
    "    n_sessions_per_user.min(), \n",
    "    n_sessions_per_user.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dataset.groupby('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.groupby.DataFrameGroupBy object at 0x000001EE8B66FE88>\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular items: [('443', 1983), ('1065', 1533), ('67', 1471), ('1622', 1220), ('2308', 1215)]\n"
     ]
    }
   ],
   "source": [
    "print('Most popular items: {}'.format(cnt.most_common(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='split_the_dataset'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let's split the dataset by assigning the **last session** of every user to the **test set**, and **all the previous** ones to the **training set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sessions: 48399 - Test sessions: 17850\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = last_session_out_split(dataset)\n",
    "print(\"Train sessions: {} - Test sessions: {}\".format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>ts</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>223</td>\n",
       "      <td>[3772, 3953]</td>\n",
       "      <td>1419418147</td>\n",
       "      <td>15861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>[245, 1271, 379]</td>\n",
       "      <td>1419433841</td>\n",
       "      <td>15861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>[245, 1197, 4307, 3868]</td>\n",
       "      <td>1421674741</td>\n",
       "      <td>15861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>245</td>\n",
       "      <td>[409, 234, 2334, 2431, 231, 4738, 219, 2403]</td>\n",
       "      <td>1421679507</td>\n",
       "      <td>15861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>353</td>\n",
       "      <td>[4255, 652, 4256, 4257, 4256, 2247]</td>\n",
       "      <td>1420927951</td>\n",
       "      <td>4296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>354</td>\n",
       "      <td>[652, 4257, 4255, 4256, 2247, 652, 4256, 2247,...</td>\n",
       "      <td>1420935007</td>\n",
       "      <td>4296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>355</td>\n",
       "      <td>[793, 3489, 3090, 1762]</td>\n",
       "      <td>1420979477</td>\n",
       "      <td>4296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>357</td>\n",
       "      <td>[793, 3489]</td>\n",
       "      <td>1421003874</td>\n",
       "      <td>4296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>386</td>\n",
       "      <td>[1251, 1255, 1252, 3178, 1256, 1253, 443, 1254...</td>\n",
       "      <td>1420522353</td>\n",
       "      <td>30980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>388</td>\n",
       "      <td>[1097, 276, 7182, 1254, 1864, 7431, 1255, 274]</td>\n",
       "      <td>1420646888</td>\n",
       "      <td>30980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id                                           sequence          ts  \\\n",
       "1          223                                       [3772, 3953]  1419418147   \n",
       "2          226                                   [245, 1271, 379]  1419433841   \n",
       "3          243                            [245, 1197, 4307, 3868]  1421674741   \n",
       "4          245       [409, 234, 2334, 2431, 231, 4738, 219, 2403]  1421679507   \n",
       "6          353                [4255, 652, 4256, 4257, 4256, 2247]  1420927951   \n",
       "7          354  [652, 4257, 4255, 4256, 2247, 652, 4256, 2247,...  1420935007   \n",
       "8          355                            [793, 3489, 3090, 1762]  1420979477   \n",
       "9          357                                        [793, 3489]  1421003874   \n",
       "11         386  [1251, 1255, 1252, 3178, 1256, 1253, 443, 1254...  1420522353   \n",
       "12         388     [1097, 276, 7182, 1254, 1864, 7431, 1255, 274]  1420646888   \n",
       "\n",
       "    user_id  \n",
       "1     15861  \n",
       "2     15861  \n",
       "3     15861  \n",
       "4     15861  \n",
       "6      4296  \n",
       "7      4296  \n",
       "8      4296  \n",
       "9      4296  \n",
       "11    30980  \n",
       "12    30980  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>ts</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122</td>\n",
       "      <td>[1762, 3700, 638]</td>\n",
       "      <td>1420059172</td>\n",
       "      <td>2432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>246</td>\n",
       "      <td>[245, 1197, 4307, 3868]</td>\n",
       "      <td>1421682592</td>\n",
       "      <td>15861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>359</td>\n",
       "      <td>[1762]</td>\n",
       "      <td>1421018535</td>\n",
       "      <td>4296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>404</td>\n",
       "      <td>[67, 471, 3551, 2466, 1475, 2267]</td>\n",
       "      <td>1421697722</td>\n",
       "      <td>30980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>657</td>\n",
       "      <td>[665, 2204, 2205, 2206, 2207]</td>\n",
       "      <td>1421713004</td>\n",
       "      <td>5953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>689</td>\n",
       "      <td>[3208, 531, 3081, 2285]</td>\n",
       "      <td>1421576868</td>\n",
       "      <td>8677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1614</td>\n",
       "      <td>[3492, 2418, 2420, 1209, 3933, 7083, 3491, 247...</td>\n",
       "      <td>1421049831</td>\n",
       "      <td>12789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1861</td>\n",
       "      <td>[6315, 3391]</td>\n",
       "      <td>1421422293</td>\n",
       "      <td>17917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2042</td>\n",
       "      <td>[2211, 2208, 2205]</td>\n",
       "      <td>1421066642</td>\n",
       "      <td>8266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2218</td>\n",
       "      <td>[788, 2353]</td>\n",
       "      <td>1421672287</td>\n",
       "      <td>17265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id                                           sequence          ts  \\\n",
       "0          122                                  [1762, 3700, 638]  1420059172   \n",
       "5          246                            [245, 1197, 4307, 3868]  1421682592   \n",
       "10         359                                             [1762]  1421018535   \n",
       "20         404                  [67, 471, 3551, 2466, 1475, 2267]  1421697722   \n",
       "22         657                      [665, 2204, 2205, 2206, 2207]  1421713004   \n",
       "25         689                            [3208, 531, 3081, 2285]  1421576868   \n",
       "28        1614  [3492, 2418, 2420, 1209, 3933, 7083, 3491, 247...  1421049831   \n",
       "29        1861                                       [6315, 3391]  1421422293   \n",
       "30        2042                                 [2211, 2208, 2205]  1421066642   \n",
       "37        2218                                        [788, 2353]  1421672287   \n",
       "\n",
       "    user_id  \n",
       "0      2432  \n",
       "5     15861  \n",
       "10     4296  \n",
       "20    30980  \n",
       "22     5953  \n",
       "25     8677  \n",
       "28    12789  \n",
       "29    17917  \n",
       "30     8266  \n",
       "37    17265  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fitting'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fitting the recommender\n",
    "\n",
    "Here we fit the recommedation algorithm over the sessions in the training set.  \n",
    "This recommender is based on the following paper:\n",
    "\n",
    "_Rendle, S., Freudenthaler, C., & Schmidt-Thieme, L. (2010). Factorizing personalized Markov chains for next-basket recommendation. Proceedings of the 19th International Conference on World Wide Web - WWW ’10, 811_\n",
    "\n",
    "In short, FPMC factorizes a personalized order-1 transition tensor using Tensor Factorization with pairwise loss function akin to BPR (Bayesian Pairwise Ranking).\n",
    "\n",
    "<img src=\"images/fpmc.png\" width=\"200px\" />\n",
    "\n",
    "TF allows to impute values for the missing transitions between items for each user. For this reason, FPMC can be used for generating _personalized_ recommendations in session-aware recommenders as well.\n",
    "\n",
    "In this notebook, you will be able to change the number of latent factors and a few other learning hyper-parameters and see the impact on the recommendation quality.\n",
    "\n",
    "The class `FPMCRecommender` has the following initialization hyper-parameters:\n",
    "* `n_factor`: (optional) the number of latent factors\n",
    "* `learn_rate`: (optional) the learning rate\n",
    "* `regular`: (optional) the L2 regularization coefficient\n",
    "* `n_epoch`: (optional) the number of training epochs\n",
    "* `n_neg`: (optional) the number of negative samples used in BPR learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-07 10:58:31,906 - INFO - epoch 0 done\n",
      "2019-11-07 10:58:33,044 - INFO - epoch 1 done\n",
      "2019-11-07 10:58:34,194 - INFO - epoch 2 done\n",
      "2019-11-07 10:58:35,334 - INFO - epoch 3 done\n",
      "2019-11-07 10:58:36,526 - INFO - epoch 4 done\n"
     ]
    }
   ],
   "source": [
    "recommender = FPMCRecommender(n_factor=16,\n",
    "                              n_epoch=5)\n",
    "recommender.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='seq_evaluation'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Sequential evaluation\n",
    "\n",
    "In the evaluation of sequence-aware recommenders, each sequence in the test set is split into:\n",
    "- the _user profile_, used to compute recommendations, is composed by the first *k* events in the sequence;\n",
    "- the _ground truth_, used for performance evaluation, is composed by the remainder of the sequence.\n",
    "\n",
    "In the cells below, you can control the dimension of the _user profile_ by assigning a **positive** value to `GIVEN_K`, which correspond to the number of events from the beginning of the sequence that will be assigned to the initial user profile. This ensures that each user profile in the test set will have exactly the same initial size, but the size of the ground truth will change for every sequence.\n",
    "\n",
    "Alternatively, by assigning a **negative** value to `GIVEN_K`, you will set the initial size of the _ground truth_. In this way the _ground truth_ will have the same size for all sequences, but the dimension of the user profile will differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = {'precision':precision, \n",
    "           'recall':recall,\n",
    "           'mrr': mrr}\n",
    "TOPN = 10 # length of the recommendation list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eval_seq_rev'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Evaluation with sequentially revealed user-profiles\n",
    "\n",
    "Here we evaluate the quality of the recommendations in a setting in which user profiles are revealed _sequentially_.\n",
    "\n",
    "The _user profile_ starts from the first `GIVEN_K` events (or, alternatively, from the last `-GIVEN_K` events if `GIVEN_K<0`).  \n",
    "The recommendations are evaluated against the next `LOOK_AHEAD` events (the _ground truth_).  \n",
    "The _user profile_ is next expanded to the next `STEP` events, the ground truth is scrolled forward accordingly, and the evaluation continues until the sequence ends.\n",
    "\n",
    "In typical **next-item recommendation**, we start with `GIVEN_K=1`, generate a set of **alternatives** that will evaluated against the next event in the sequence (`LOOK_AHEAD=1`), move forward of one step (`STEP=1`) and repeat until the sequence ends.\n",
    "\n",
    "You can set the `LOOK_AHEAD='all'` to see what happens if you had to recommend a **whole sequence** instead of a set of a set of alternatives to a user.\n",
    "\n",
    "NOTE: Metrics are averaged over each sequence first, then averaged over all test sequences.\n",
    "\n",
    "** (TODO) Try out with different evaluation settings to see how the recommandation quality changes. **\n",
    "\n",
    "\n",
    "![](gifs/sequential_eval.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIVEN_K=1, LOOK_AHEAD=1, STEP=1 corresponds to the classical next-item evaluation\n",
    "GIVEN_K = 1\n",
    "LOOK_AHEAD = 1\n",
    "STEP=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200 sequences available for evaluation (9200 users)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 9200/9200 [13:40<00:00, 11.21it/s]\n"
     ]
    }
   ],
   "source": [
    "test_sequences, test_users = get_test_sequences_and_users(test_data, GIVEN_K, train_data['user_id'].values) # we need user ids now!\n",
    "print('{} sequences available for evaluation ({} users)'.format(len(test_sequences), len(np.unique(test_users))))\n",
    "\n",
    "results = evaluation.sequential_evaluation(recommender,\n",
    "                                           test_sequences=test_sequences,\n",
    "                                           users=test_users,\n",
    "                                           given_k=GIVEN_K,\n",
    "                                           look_ahead=LOOK_AHEAD,\n",
    "                                           evaluation_functions=METRICS.values(),\n",
    "                                           top_n=TOPN,\n",
    "                                           scroll=True,  # scrolling averages metrics over all profile lengths\n",
    "                                           step=STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>ts</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>223</td>\n",
       "      <td>[3772, 3953]</td>\n",
       "      <td>1419418147</td>\n",
       "      <td>15861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>[245, 1271, 379]</td>\n",
       "      <td>1419433841</td>\n",
       "      <td>15861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>[245, 1197, 4307, 3868]</td>\n",
       "      <td>1421674741</td>\n",
       "      <td>15861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>245</td>\n",
       "      <td>[409, 234, 2334, 2431, 231, 4738, 219, 2403]</td>\n",
       "      <td>1421679507</td>\n",
       "      <td>15861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>353</td>\n",
       "      <td>[4255, 652, 4256, 4257, 4256, 2247]</td>\n",
       "      <td>1420927951</td>\n",
       "      <td>4296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                                      sequence          ts  \\\n",
       "1         223                                  [3772, 3953]  1419418147   \n",
       "2         226                              [245, 1271, 379]  1419433841   \n",
       "3         243                       [245, 1197, 4307, 3868]  1421674741   \n",
       "4         245  [409, 234, 2334, 2431, 231, 4738, 219, 2403]  1421679507   \n",
       "6         353           [4255, 652, 4256, 4257, 4256, 2247]  1420927951   \n",
       "\n",
       "   user_id  \n",
       "1    15861  \n",
       "2    15861  \n",
       "3    15861  \n",
       "4    15861  \n",
       "6     4296  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['245', '1197', '4307', '3868']),\n",
       "       list(['67', '471', '3551', '2466', '1475', '2267']),\n",
       "       list(['665', '2204', '2205', '2206', '2207']), ...,\n",
       "       list(['431', '2445']),\n",
       "       list(['419', '930', '419', '908', '3493', '5294', '5297', '5299', '5296']),\n",
       "       list(['40', '3319', '1546', '1484', '1417', '155', '3495', '3188'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15861, 30980,  5953, ..., 26213,  4503, 12934], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential evaluation (GIVEN_K=1, LOOK_AHEAD=1, STEP=1)\n",
      "\tprecision@10: 0.0232\n",
      "\trecall@10: 0.2319\n",
      "\tmrr@10: 0.1077\n"
     ]
    }
   ],
   "source": [
    "print('Sequential evaluation (GIVEN_K={}, LOOK_AHEAD={}, STEP={})'.format(GIVEN_K, LOOK_AHEAD, STEP))\n",
    "for mname, mvalue in zip(METRICS.keys(), results):\n",
    "    print('\\t{}@{}: {:.4f}'.format(mname, TOPN, mvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eval_static'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Evaluation with \"static\" user-profiles\n",
    "\n",
    "Here we evaluate the quality of the recommendations in a setting in which user profiles are instead _static_.\n",
    "\n",
    "The _user profile_ starts from the first `GIVEN_K` events (or, alternatively, from the last `-GIVEN_K` events if `GIVEN_K<0`).  \n",
    "The recommendations are evaluated against the next `LOOK_AHEAD` events (the _ground truth_).  \n",
    "\n",
    "The user profile is *not extended* and the ground truth *doesn't move forward*.\n",
    "This allows to obtain \"snapshots\" of the recommendation performance for different user profile and ground truth lenghts.\n",
    "\n",
    "Also here you can set the `LOOK_AHEAD='all'` to see what happens if you had to recommend a **whole sequence** instead of a set of a set of alternatives to a user.\n",
    "\n",
    "**(TODO) Try out with different evaluation settings to see how the recommandation quality changes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIVEN_K = 1\n",
    "LOOK_AHEAD = 'all'\n",
    "STEP=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences, test_users = get_test_sequences_and_users(test_data, GIVEN_K, train_data['user_id'].values) # we need user ids now!\n",
    "print('{} sequences available for evaluation ({} users)'.format(len(test_sequences), len(np.unique(test_users))))\n",
    "\n",
    "results = evaluation.sequential_evaluation(recommender,\n",
    "                                           test_sequences=test_sequences,\n",
    "                                           users=test_users,\n",
    "                                           given_k=GIVEN_K,\n",
    "                                           look_ahead=LOOK_AHEAD,\n",
    "                                           evaluation_functions=METRICS.values(),\n",
    "                                           top_n=TOPN,\n",
    "                                           scroll=False  # notice that scrolling is disabled!\n",
    "                                          )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sequential evaluation (GIVEN_K={}, LOOK_AHEAD={}, STEP={})'.format(GIVEN_K, LOOK_AHEAD, STEP))\n",
    "for mname, mvalue in zip(METRICS.keys(), results):\n",
    "    print('\\t{}@{}: {:.4f}'.format(mname, TOPN, mvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='next-item'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis of next-item recommendation\n",
    "\n",
    "Here we propose to analyse the performance of the recommender system in the scenario of *next-item recommendation* over the following dimensions:\n",
    "\n",
    "* the *length* of the **recommendation list**, and\n",
    "* the *length* of the **user profile**.\n",
    "\n",
    "NOTE: This evaluation is by no means exhaustive, as different the hyper-parameters of the recommendation algorithm should be *carefully tuned* before drawing any conclusions. Unfortunately, given the time constraints for this tutorial, we had to leave hyper-parameter tuning out. A very useful reference about careful evaluation of (session-based) recommenders can be found at:\n",
    "\n",
    "*  Evaluation of Session-based Recommendation Algorithms, Ludewig and Jannach, 2018 ([paper](https://arxiv.org/abs/1803.09587))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='next-item_list_length'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Evaluation for different recommendation list lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIVEN_K = 1\n",
    "LOOK_AHEAD = 1\n",
    "STEP = 1\n",
    "topn_list = [1, 5, 10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200 sequences available for evaluation (9200 users)\n"
     ]
    }
   ],
   "source": [
    "# ensure that all sequences have the same minimum length \n",
    "test_sequences, test_users = get_test_sequences_and_users(test_data, GIVEN_K, train_data['user_id'].values) # we need user ids now!\n",
    "print('{} sequences available for evaluation ({} users)'.format(len(test_sequences), len(np.unique(test_users))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = []\n",
    "\n",
    "for topn in topn_list:\n",
    "    print('Evaluating recommendation lists with length: {}'.format(topn))\n",
    "    res_tmp = evaluation.sequential_evaluation(recommender,\n",
    "                                               test_sequences=test_sequences,\n",
    "                                               users=test_users,\n",
    "                                               given_k=GIVEN_K,\n",
    "                                               look_ahead=LOOK_AHEAD,\n",
    "                                               evaluation_functions=METRICS.values(),\n",
    "                                               top_n=topn,\n",
    "                                               scroll=True,  # here we average over all profile lengths\n",
    "                                               step=STEP)\n",
    "    mvalues = list(zip(METRICS.keys(), res_tmp))\n",
    "    res_list.append((topn, mvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show separate plots per metric\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(METRICS), figsize=(15,5))\n",
    "res_list_t = list(zip(*res_list))\n",
    "for midx, metric in enumerate(METRICS):\n",
    "    mvalues = [res_list_t[1][j][midx][1] for j in range(len(res_list_t[1]))]\n",
    "    ax = axes[midx]\n",
    "    ax.plot(topn_list, mvalues)\n",
    "    ax.set_title(metric)\n",
    "    ax.set_xticks(topn_list)\n",
    "    ax.set_xlabel('List length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='next-item_profile_length'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Evaluation for different user profile lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_k_list = [1, 2, 3, 4]\n",
    "LOOK_AHEAD = 1\n",
    "STEP = 1\n",
    "TOPN = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = []\n",
    "\n",
    "for gk in given_k_list:\n",
    "    print('Evaluating profiles having length: {}'.format(gk))\n",
    "    res_tmp = evaluation.sequential_evaluation(recommender,\n",
    "                                               test_sequences=test_sequences,\n",
    "                                               users=test_users,\n",
    "                                               given_k=gk,\n",
    "                                               look_ahead=LOOK_AHEAD,\n",
    "                                               evaluation_functions=METRICS.values(),\n",
    "                                               top_n=TOPN,\n",
    "                                               scroll=False,  # here we stop at each profile length\n",
    "                                               step=STEP)\n",
    "    mvalues = list(zip(METRICS.keys(), res_tmp))\n",
    "    res_list.append((gk, mvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show separate plots per metric\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(METRICS), figsize=(15,5))\n",
    "res_list_t = list(zip(*res_list))\n",
    "for midx, metric in enumerate(METRICS):\n",
    "    mvalues = [res_list_t[1][j][midx][1] for j in range(len(res_list_t[1]))]\n",
    "    ax = axes[midx]\n",
    "    ax.plot(given_k_list, mvalues)\n",
    "    ax.set_title(metric)\n",
    "    ax.set_xticks(given_k_list)\n",
    "    ax.set_xlabel('Profile length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srs",
   "language": "python",
   "name": "srs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
